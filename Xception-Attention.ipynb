{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os, cv2, re, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from keras import layers, models, optimizers\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = '/home/skpunisher557/capstone/train/'\n",
    "\n",
    "ROWS = 299\n",
    "COLS = 299\n",
    "CHANNELS = 3\n",
    "\n",
    "MURA_train = [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR)]\n",
    "\n",
    "\n",
    "\n",
    "def read_image(file_path):\n",
    "    img = cv2.imread(file_path, cv2.IMREAD_COLOR) #cv2.IMREAD_GRAYSCALE\n",
    "    return cv2.resize(img, (ROWS, COLS), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "\n",
    "def prep_data(images):\n",
    "    count = len(images)\n",
    "    data = np.ndarray((count, CHANNELS, ROWS, COLS), dtype=np.uint8)\n",
    "\n",
    "    for i, image_file in enumerate(images):\n",
    "        image = read_image(image_file)\n",
    "        data[i] = image.T\n",
    "        if i%250 == 0: print('Processed {} of {}'.format(i, count))\n",
    "    \n",
    "    return data\n",
    "\n",
    "train = prep_data(MURA_train)\n",
    "\n",
    "print(\"Train shape: {}\".format(train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    return [ atoi(c) for c in re.split('(\\d+)', text) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(list_of_images):\n",
    "    \"\"\"\n",
    "    Returns two arrays: \n",
    "        x is an array of resized images\n",
    "        y is an array of labels\n",
    "    \"\"\"\n",
    "    x = [] # images as arrays\n",
    "    y = [] # labels\n",
    "    \n",
    "    for image in list_of_images:\n",
    "        x.append(cv2.resize(cv2.imread(image), (299,299)))#, interpolation=cv2.INTER_CUBIC))\n",
    "    \n",
    "    for i in list_of_images:\n",
    "        if 'positive' in i:\n",
    "            y.append(1)\n",
    "        else:\n",
    "            y.append(0)\n",
    "            \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = prepare_data(MURA_train)\n",
    "print(K.image_data_format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X,Y, test_size=0.2, random_state=1)\n",
    "nb_train_samples = len(X_train)\n",
    "nb_validation_samples = len(X_val)\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow(np.array(X), Y, batch_size=batch_size)\n",
    "validation_generator = val_datagen.flow(np.array(X), Y, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.xception import Xception,preprocess_input,decode_predictions\n",
    "base_model = Xception(include_top=False, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)\n",
    "base_model.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_features = Input(base_model.get_output_shape_at(0)[1:], name = 'feature_input')\n",
    "pt_depth = base_model.get_output_shape_at(0)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_features = BatchNormalization()(pt_features)\n",
    "\n",
    "attn_layer = Conv2D(128, kernel_size = (1,1), padding = 'same', activation = 'elu')(bn_features)\n",
    "attn_layer = Conv2D(32, kernel_size = (1,1), padding = 'same', activation = 'elu')(attn_layer)\n",
    "attn_layer = Conv2D(16, kernel_size = (1,1), padding = 'same', activation = 'elu')(attn_layer)\n",
    "attn_layer = AvgPool2D((2,2), strides = (1,1), padding = 'same')(attn_layer)\n",
    "attn_layer = Conv2D(1, kernel_size = (1,1), padding = 'valid', activation = 'sigmoid')(attn_layer)\n",
    "\n",
    "up_c2_w = np.ones((1, 1, 1, pt_depth))\n",
    "up_c2 = Conv2D(pt_depth, kernel_size = (1,1), padding = 'same', \n",
    "               activation = 'linear', use_bias = False, weights = [up_c2_w])\n",
    "up_c2.trainable = False\n",
    "attn_layer = up_c2(attn_layer)\n",
    "\n",
    "mask_features = multiply([attn_layer, bn_features])\n",
    "gap_features = GlobalAveragePooling2D()(mask_features)\n",
    "gap_mask = GlobalAveragePooling2D()(attn_layer)\n",
    "# to account for missing values from the attention model\n",
    "gap = Lambda(lambda x: x[0]/x[1], name = 'RescaleGAP')([gap_features, gap_mask])\n",
    "gap_dr = Dropout(0.5)(gap)\n",
    "gap_features1 = GlobalAveragePooling2D()(mask_features)\n",
    "gap_mask1 = GlobalAveragePooling2D()(attn_layer)\n",
    "#to account for missing values from the attention model\n",
    "gap1 = Lambda(lambda x: x[0]/x[1], name = 'RescaleGAP')([gap_features1, gap_mask1])\n",
    "gap_dr1 = Dropout(0.5)(gap1)\n",
    "gap_features2 = GlobalAveragePooling2D()(mask_features)\n",
    "gap_mask2 = GlobalAveragePooling2D()(attn_layer)\n",
    "gap2 = Lambda(lambda x: x[0]/x[1], name = 'RescaleGAP')([gap_features2, gap_mask2])\n",
    "gap_dr2 = Dropout(0.5)(gap2)\n",
    "\n",
    "dr_steps = Dropout(0.5)(Dense(128, activation = 'elu')(gap_dr2))\n",
    "out_layer = Dense(1, activation = 'sigmoid')(dr_steps)\n",
    "\n",
    "attn_model = Model(inputs = [pt_features], outputs = [out_layer], name = 'attention_model')\n",
    "\n",
    "attn_model.compile(optimizer = Adam(lr = 1e-3, beta_1=0.9, beta_2 = 0.999, epsilon = None, decay = 0.0, amsgrad = True),\n",
    "              loss = 'binary_crossentropy', metrics = ['binary_accuracy'])\n",
    "\n",
    "attn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(name = 'combined_model')\n",
    "model.add(base_model)\n",
    "model.add(attn_model)\n",
    "model.compile(optimizer = Adam(lr = 1e-3, beta_1=0.9, beta_2 = 0.999, epsilon = None, decay = 0.0, amsgrad = True),\n",
    "              loss = 'binary_crossentropy', metrics = ['binary_accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('Xception-Attention-best-again-150epochs.hdf5',\n",
    "monitor='val_binary_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='max', period=1)\n",
    "\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "\n",
    "history = model.fit_generator(train_generator, steps_per_epoch=nb_train_samples // batch_size, epochs=150, \n",
    "callbacks=callbacks_list, validation_data=validation_generator, validation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Xception-Attention-again-150epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12,6)\n",
    "\n",
    "acc = history.history['binary_accuracy']\n",
    "val_acc = history.history['val_binary_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.plot(epochs, acc, 'red', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'blue', label='Validation acc')\n",
    "plt.legend()\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
